{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files11\\Anaconda\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.platform import gfile\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "iterations = 2000\n",
    "epoch = 100\n",
    "eval_every = 5\n",
    "test_iteration = 15\n",
    "height = 20\n",
    "width = 44\n",
    "num_labels = 0\n",
    "train_path = \"G:/datasets/train\"\n",
    "test_path = \"G:/datasets/test\"\n",
    "learning_rate = 0.001\n",
    "logdir = '/log'\n",
    "test_logdir = '/test_log'\n",
    "label_to_index_map = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init(path) :\n",
    "    labels = os.listdir(path)\n",
    "    index = 0\n",
    "    for label in labels :\n",
    "        label_to_index_map[label] = index\n",
    "        index+=1\n",
    "    global num_labels\n",
    "    num_labels = len(label_to_index_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoding_labels(label) :\n",
    "    encoding = [0] * len(label_to_index_map)\n",
    "    encoding[label_to_index_map[label]] = 1\n",
    "    return encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mfccs(wave_path, pad_width = width) :\n",
    "    wave, sr = librosa.load(wave_path, mono=True)\n",
    "    mfccs = librosa.feature.mfcc(y=wave, sr=sr, n_mfcc=height)\n",
    "    mfccs = np.pad(mfccs, ((0,0), (0, pad_width - len(mfccs[0]))), mode = 'constant')\n",
    "    return mfccs\n",
    "                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(path) :\n",
    "    y = []\n",
    "    X = []\n",
    "    path = os.path.join(path, '*', '*.wav')\n",
    "    waves = gfile.Glob(path)\n",
    "    for wave_path in waves :\n",
    "        _, label = os.path.split(os.path.dirname(wave_path))\n",
    "        X.append(get_mfccs(wave_path))\n",
    "        y.append(encoding_labels(label))\n",
    "        if len(y) % 400 == 0 :\n",
    "            print(label)\n",
    "    return X, y\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_model(input) :\n",
    "    with tf.name_scope(\"Conv1\") :\n",
    "        input4d = tf.reshape(input, [-1, height, width, 1])\n",
    "        w1 = tf.Variable(tf.truncated_normal([9, 8, 1, 44], stddev=0.01), name=\"W\")\n",
    "        b1 = tf.Variable(tf.zeros(44), name=\"B\")\n",
    "        conv1 = tf.nn.conv2d(input4d, w1, strides=[1,1,1,1], padding=\"SAME\")\n",
    "        act1 = tf.nn.relu(conv1 + b1)\n",
    "        #drop1 = tf.nn.dropout(act1, dropout)\n",
    "        max_pool1 = tf.nn.max_pool(act1, ksize=[1,2,2,1], strides=[1,2,2,1], padding=\"SAME\")\n",
    "    \n",
    "    with tf.name_scope(\"Conv2\") :\n",
    "        w2 = tf.Variable(tf.truncated_normal([3, 4, 44, 44], stddev=0.01), name=\"W\")\n",
    "        b2 = tf.Variable(tf.zeros(44), name=\"B\")\n",
    "        conv2 = tf.nn.conv2d(max_pool1, w2, strides=[1,1,1,1], padding=\"SAME\")\n",
    "        act2 = tf.nn.relu(conv2+b2)\n",
    "        #drop2 = tf.nn.dropout(act2, dropout)\n",
    "        max_pool2 = tf.nn.max_pool(act2, ksize=[1,2,2,1], strides=[1,2,2,1], padding=\"SAME\")\n",
    "        \n",
    "    shape_of_conv2 = max_pool2.get_shape()\n",
    "    count = int(shape_of_conv2[1] * shape_of_conv2[2] * shape_of_conv2[3])\n",
    "    reshaped_output = tf.reshape(max_pool2, [-1, count])\n",
    "    \n",
    "    with tf.name_scope(\"FC1\") :\n",
    "        inputFC1_count = count\n",
    "        outputFC1_count = inputFC1_count // 5\n",
    "        w3 = tf.Variable(tf.truncated_normal([inputFC1_count, outputFC1_count ], stddev = 0.01))\n",
    "        b3 = tf.Variable(tf.zeros(outputFC1_count))\n",
    "        fc1 = tf.add(tf.matmul(reshaped_output, w3), b3)\n",
    "        fc1 = tf.nn.relu(fc1)\n",
    "   \n",
    "    with tf.name_scope(\"FC2\") :\n",
    "        inputFC2_count = outputFC1_count\n",
    "        outputFC2_count = inputFC2_count // 4\n",
    "        w4 = tf.Variable(tf.truncated_normal([inputFC2_count, outputFC2_count], stddev = 0.01))\n",
    "        b4 = tf.Variable(tf.zeros(outputFC2_count))\n",
    "        fc2 = tf.add(tf.matmul(fc1, w4), b4)\n",
    "        fc2 = tf.nn.relu(fc2)\n",
    "     \n",
    "        \n",
    "    with tf.name_scope(\"FC3\") :\n",
    "        inputFC3_count = outputFC2_count\n",
    "        outputFC3_count = num_labels\n",
    "        w5 = tf.Variable(tf.truncated_normal([inputFC3_count, outputFC3_count], stddev = 0.01))\n",
    "        b5 = tf.Variable(tf.zeros(outputFC3_count))\n",
    "        fc3 = tf.add(tf.matmul(fc2, w5), b5)\n",
    "    \n",
    "    return fc3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main() :\n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    X = tf.placeholder(tf.float32, shape=(None, height, width), name=\"input\")\n",
    "    y = tf.placeholder(tf.int32, shape=(None, num_labels), name=\"labels\")\n",
    "    \n",
    "    #dropout = tf.placeholder(tf.float32, name=\"dropout\")\n",
    "    \n",
    "    logits = my_model(X)\n",
    "    \n",
    "    with tf.name_scope(\"loss\") :\n",
    "        loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=logits))\n",
    "        tf.summary.scalar(\"loss\", loss)\n",
    "        \n",
    "    with tf.name_scope(\"train\") :\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate)\n",
    "        train_step = optimizer.minimize(loss)\n",
    "        \n",
    "    with tf.name_scope(\"accuracy\") :\n",
    "        predicted = tf.argmax(logits, 1)\n",
    "        truth = tf.argmax(y, 1)\n",
    "        correct_prediction = tf.equal(predicted, truth)\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "        confusion_matrix = tf.confusion_matrix(truth, predicted, num_classes = num_labels)\n",
    "        tf.summary.scalar(\"accuracy\", accuracy)\n",
    "        \n",
    "    with tf.Session() as sess :\n",
    "        summary = tf.summary.merge_all()\n",
    "        saver = tf.train.Saver()\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        writer = tf.summary.FileWriter(logdir)\n",
    "        writer.add_graph(sess.graph)\n",
    "\n",
    "        print(\"Понеслось\\n\")\n",
    "        X_train, y_train = get_data(train_path)\n",
    "        X_test, y_test = get_data(test_path)\n",
    "        number = len(X_train)\n",
    "        start_time = time.time()\n",
    "        for i in range(epoch) :\n",
    "            X_train, y_train = shuffle(X_train, y_train)\n",
    "            for l in range(0, number, batch_size) :\n",
    "                end = l + batch_size\n",
    "                X_batch, y_batch = X_train[l:end], y_train[l:end]\n",
    "                sess.run(train_step, feed_dict = {X: X_batch, y: y_batch})\n",
    "                \n",
    "            num_examples = len(X_test)\n",
    "            total_accuracy = 0\n",
    "            for k in range(0, num_examples,batch_size) :\n",
    "                X_batchT, y_batchT = X_test[k:k+batch_size], y_test[k:k+batch_size]\n",
    "                res_accuracy = sess.run(accuracy, feed_dict={X: X_batchT, y: y_batchT})\n",
    "                total_accuracy += (res_accuracy * len(X_batchT))\n",
    "                if i % (eval_every * 20) == 0 :\n",
    "                    saver.save(sess, \"./smthnn.ckpt\")\n",
    "            print(\"Epoch:\", i, \" Accuracy:\", total_accuracy / num_examples )\n",
    "            print(df)\n",
    "\n",
    "        print(\"\\nTotal training time\", time.time()-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Понеслось\n",
      "\n",
      "bed\n",
      "bed\n",
      "bed\n",
      "bed\n",
      "bird\n",
      "bird\n",
      "bird\n",
      "bird\n",
      "cat\n",
      "cat\n",
      "cat\n",
      "cat\n",
      "dog\n",
      "dog\n",
      "dog\n",
      "dog\n",
      "down\n",
      "down\n",
      "down\n",
      "down\n",
      "down\n",
      "down\n",
      "eight\n",
      "eight\n",
      "eight\n",
      "eight\n",
      "eight\n",
      "eight\n",
      "five\n",
      "five\n",
      "five\n",
      "five\n",
      "five\n",
      "five\n",
      "four\n",
      "four\n",
      "four\n",
      "four\n",
      "four\n",
      "four\n",
      "go\n",
      "go\n",
      "go\n",
      "go\n",
      "go\n",
      "go\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'X_batchT' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-d18d65947b92>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0minit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-17-a08c9deb29ff>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     43\u001b[0m                 \u001b[0mX_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m                 \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mX_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0my_batch\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m                 \u001b[0mtrain_confusion_matrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mX_batchT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0my_batchT\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m                 \u001b[0mheader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabel_to_index_map\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m                 \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_confusion_matrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnum_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mheader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'X_batchT' referenced before assignment"
     ]
    }
   ],
   "source": [
    "init(train_path)\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
